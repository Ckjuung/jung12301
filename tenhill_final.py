
import requests
import xmltodict
import pandas as pd
import os
import json
from datetime import datetime

service_key = 'DBL9/jevAhTCfpDi5RqbnF61jt1lxJGlxxUSW/7mv4GB9bDJk6F1V+2izfb51UFSFtAGXxQ89Xy89pk4VFOMuQ=='
TELEGRAM_TOKEN = '7360228257:AAF9V2WcMmm6zP9SW4HPeh2RGpS_f672gN4'
CHAT_ID = '459970561'
SEEN_FILE = "seen.json"

if os.path.exists(SEEN_FILE):
    with open(SEEN_FILE, 'r') as f:
        seen = set(json.load(f))
else:
    seen = set()

start = datetime(2025, 3, 1)
today = datetime.today()
months = []
while start <= today:
    months.append(start.strftime("%Y%m"))
    if start.month == 12:
        start = datetime(start.year + 1, 1, 1)
    else:
        start = datetime(start.year, start.month + 1, 1)

def fetch_data(lawd_cd):
    all_rows = []
    for deal_ymd in months:
        url = "http://apis.data.go.kr/1613000/RTMSDataSvcAptTradeDev/getRTMSDataSvcAptTradeDev"
        params = {
            'serviceKey': service_key,
            'LAWD_CD': lawd_cd,
            'DEAL_YMD': deal_ymd,
            'numOfRows': '1000',
            'pageNo': '1'
        }
        res = requests.get(url, params=params)
        data = xmltodict.parse(res.text)
        if 'response' in data and 'body' in data['response'] and 'items' in data['response']['body']:
            items = data['response']['body']['items']
            if items and 'item' in items:
                rows = items['item']
                if isinstance(rows, list):
                    all_rows.extend(rows)
                else:
                    all_rows.append(rows)
    return pd.DataFrame(all_rows)


# âœ… ì§€ì—­ë³„ ë°ì´í„° ìˆ˜ì§‘
df1 = fetch_data("11200")  # ì„±ë™êµ¬
df2 = fetch_data("11680")  # ê°•ë‚¨êµ¬
df3 = fetch_data("11590")  # ë™ìž‘êµ¬
df4 = fetch_data("11710")  # ì†¡íŒŒêµ¬
df = pd.concat([df1, df2, df3, df4], ignore_index=True)
df['excluUseAr'] = df['excluUseAr'].astype(float)

# âœ… í•„í„° ì¡°ê±´
cond_centras = (df['aptNm'].str.contains('ì„¼íŠ¸ë¼ìŠ¤')) & (df['umdNm'] == 'í•˜ì™•ì‹­ë¦¬ë™') & (df['excluUseAr'].between(83.0, 85.99))
cond_pureunmaeul = (df['aptNm'].str.contains('í‘¸ë¥¸ë§ˆì„')) & (df['umdNm'] == 'ì¼ì›ë™') & (df['excluUseAr'].between(83.0, 85.99))
cond_han_central = (df['aptNm'].str.contains('í‘ì„í•œê°•ì„¼íŠ¸ë ˆë¹Œ')) & (df['umdNm'] == 'í‘ì„ë™') & (df['excluUseAr'].between(83.0, 85.99))
cond_sangdo_park = (df['aptNm'].str.contains('ìƒë„íŒŒí¬ìžì´')) & (df['umdNm'] == 'ìƒë„ë™') & (df['excluUseAr'].between(83.0, 85.99))
cond_olympic = (df['aptNm'].str.contains('ì˜¬ë¦¼í”½í›¼ë¯¸ë¦¬íƒ€ìš´')) & (df['umdNm'] == 'ë¬¸ì •ë™') & (df['excluUseAr'].between(80.0, 86.0))

filtered = df[cond_centras | cond_pureunmaeul | cond_han_central | cond_sangdo_park | cond_olympic].copy()

# âœ… UID ìƒì„± ë° ì¤‘ë³µ ì œê±°
filtered['uid'] = filtered['dealYear'] + filtered['dealMonth'] + filtered['dealDay'] +                   filtered['aptNm'] + filtered['excluUseAr'].astype(str) + filtered['floor']
new_trades = filtered[~filtered['uid'].isin(seen)].copy()

# âœ… ê±°ëž˜ê¸ˆì•¡ ì²˜ë¦¬ ë° ì•Œë¦¼
if not new_trades.empty:
    new_trades['ê±°ëž˜ê¸ˆì•¡(ë§Œì›)'] = new_trades['dealAmount'].str.replace(',', '').astype(int)
    for _, row in new_trades.iterrows():
        msg = (
            f"[ì‹¤ê±°ëž˜ê°€ ì•Œë¦¼]\n"
            f"ðŸ“… {row['dealYear']}.{row['dealMonth']}.{row['dealDay']}\n"
            f"ðŸ¢ {row['aptNm']} | {row['umdNm']} | {row['excluUseAr']}ãŽ¡ | {row['floor']}ì¸µ\n"
            f"ðŸ’° {row['ê±°ëž˜ê¸ˆì•¡(ë§Œì›)']:,}ë§Œì›\n"
            f"ðŸ“Œ ê±°ëž˜ìœ í˜•: {row.get('dealingGbn', 'ì •ë³´ì—†ìŒ')}"
        )
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        requests.post(url, data={'chat_id': CHAT_ID, 'text': msg})
        seen.add(row['uid'])

# âœ… seen.json ê¸°ë¡
with open(SEEN_FILE, 'w') as f:
    json.dump(list(seen), f)
